{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Projector Weights with LLaVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "input_path = \"llava-v1.5-7b-imagenet/\"\n",
    "output_path = \"processed-llava-v1.5-7b-imagenet/\"\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "state_dict = torch.load(f\"{input_path}/mm_projector.bin\")\n",
    "original_path = \"/home/.cache/huggingface/hub/models--liuhaotian--llava-v1.5-7b/snapshots/12e054b30e8e061f423c7264bc97d4248232e965/\"\n",
    "\n",
    "for i in range(1, 3):\n",
    "    filename = f\"pytorch_model-0000{i}-of-00002.bin\"\n",
    "    original = torch.load(original_path + filename)\n",
    "\n",
    "    for k in state_dict.keys():\n",
    "        if k in original:\n",
    "            print(filename, k)\n",
    "            original[k] = state_dict[k]\n",
    "\n",
    "    torch.save(original, output_path + filename)\n",
    "\n",
    "for filename in glob.glob(original_path + \"*.json\"):\n",
    "    shutil.copy(filename, output_path)\n",
    "\n",
    "for filename in glob.glob(original_path + \"*.model\"):\n",
    "    shutil.copy(filename, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge LoRA Weights with LLaVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python ./scripts/merge_lora_weights.py --model-path ./checkpoints/llava-v1.5-7b-imagenet-1epochs-lora --model-base lmsys/vicuna-7b-v1.5 --save-model-path ./checkpoints/processed-llava-v1.5-7b-imagenet-1epochs-lora\n",
    "\n",
    "python ./scripts/merge_lora_weights.py --model-path ./checkpoints/llava-v1.5-7b-flowers-100epochs-lora --model-base lmsys/vicuna-7b-v1.5 --save-model-path ./checkpoints/processed-llava-v1.5-7b-flowers-100epochs-lora\n",
    "\n",
    "python ./scripts/merge_lora_weights.py --model-path ./checkpoints/llava-v1.5-7b-cars-100epochs-lora --model-base lmsys/vicuna-7b-v1.5 --save-model-path ./checkpoints/processed-llava-v1.5-7b-cars-100epochs-lora\n",
    "\n",
    "python ./scripts/merge_lora_weights.py --model-path ./checkpoints/llava-v1.5-7b-caltech-100epochs-lora --model-base lmsys/vicuna-7b-v1.5 --save-model-path ./checkpoints/processed-llava-v1.5-7b-caltech-100epochs-lora"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
